from langchain_community.chat_models import ChatZhipuAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import os

# ===== 1. é¦–å…ˆè®¾ç½®æ‰€æœ‰ç¦»çº¿ç¯å¢ƒå˜é‡ =====
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_DATASETS_OFFLINE'] = '1'
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# ===== 2. æ‰¾åˆ°æœ¬åœ°ç¼“å­˜çš„çœŸå®è·¯å¾„ =====
cache_dir = os.path.expanduser("~/.cache/huggingface/hub/")
print(f"ğŸ“ æœ¬åœ°ç¼“å­˜ç›®å½•: {cache_dir}")

# æŸ¥æ‰¾å®é™…ä¸‹è½½çš„æ¨¡å‹å¿«ç…§è·¯å¾„
import glob
model_paths = glob.glob(f"{cache_dir}models--sentence-transformers--all-MiniLM-L6-v2/snapshots/*/", recursive=True)
if model_paths:
    local_model_path = model_paths[0]
    print(f"âœ… æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {local_model_path}")
else:
    local_model_path = None
    print("âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ç¼“å­˜ï¼Œå°†å°è¯•ä»ç¼“å­˜åŠ è½½")

# ===== 3. é…ç½® API å¯†é’¥ =====
ZHIPU_API_KEY = "1d9ee499e7bb413aaabe015a87b7773c.3UrwmR1C6Ew1gfDy"

# ===== 4. è¯»å–æ•™æ =====
print("ğŸ“– æ­£åœ¨åŠ è½½æ•™æ...")
with open("textbook.txt", "r", encoding="utf-8") as f:
    textbook = f.read()

# ===== 5. åˆ†å‰²æ–‡æœ¬ =====
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=200,
    chunk_overlap=50,
    separators=["\n\n", "\n", "ã€‚", "ï¼›"]
)
texts = text_splitter.split_text(textbook)
print(f"âœ… åˆ†å‰²æˆ {len(texts)} ä¸ªçŸ¥è¯†ç‰‡æ®µ")

# ===== 6. åŠ è½½ embeddingsï¼ˆä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼‰=====
print("ğŸ”§ åŠ è½½ embeddings æ¨¡å‹ï¼ˆä»æœ¬åœ°ç¼“å­˜ï¼‰...")

# å¦‚æœæ‰¾åˆ°äº†æœ¬åœ°è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
if local_model_path:
    embeddings = HuggingFaceEmbeddings(
        model_name=local_model_path,  # ç›´æ¥ä½¿ç”¨æœ¬åœ°ç»å¯¹è·¯å¾„ï¼
        model_kwargs={'device': 'cpu'},
        cache_folder=cache_dir
    )
else:
    # å¦åˆ™å›é€€åˆ°æ ‡å‡†æ–¹å¼
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={'device': 'cpu'},
        cache_folder=cache_dir
    )

# ===== 7. å‘é‡æ•°æ®åº“ =====
persist_dir = "./chroma_db"

if os.path.exists(persist_dir):
    print("ğŸ—„ï¸ åŠ è½½å·²æœ‰çŸ¥è¯†åº“...")
    vectorstore = Chroma(
        persist_directory=persist_dir,
        embedding_function=embeddings
    )
    print("âœ… åŠ è½½å®Œæˆ")
else:
    print("ğŸ—„ï¸ åˆ›å»ºæ–°çŸ¥è¯†åº“...")
    vectorstore = Chroma.from_texts(
        texts=texts,
        embedding=embeddings,
        persist_directory=persist_dir
    )
    vectorstore.persist()
    print("âœ… åˆ›å»ºå®Œæˆ")

# ===== 8. åˆ›å»ºæ£€ç´¢å™¨ =====
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# ===== 9. åˆå§‹åŒ– AI =====
llm = ChatZhipuAI(
    api_key=ZHIPU_API_KEY,
    model="glm-4-flash",
    temperature=0.3
)

# ===== 10. æç¤ºè¯æ¨¡æ¿ =====
template = """ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„Pythonè€å¸ˆã€‚è¯·åŸºäºä»¥ä¸‹æ•™æå†…å®¹å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚

æ•™æå†…å®¹ï¼š
{context}

å­¦ç”Ÿé—®é¢˜ï¼š{question}

è¦æ±‚ï¼š
1. å¦‚æœæ•™æä¸­æœ‰ç›¸å…³å†…å®¹ï¼Œè¯·åŸºäºæ•™æå‡†ç¡®å›ç­”
2. å¦‚æœæ•™æä¸­æ²¡æœ‰ï¼Œè¯·è¯´"æ•™æä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œä¸è¿‡æ ¹æ®æˆ‘çš„ç†è§£ï¼š"
3. ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€ï¼Œå¯ä»¥ä¸¾ä¾‹è¯´æ˜

ä½ çš„å›ç­”ï¼š"""

prompt = PromptTemplate.from_template(template)

# ===== 11. æ ¼å¼åŒ–å‡½æ•° =====
def format_docs(docs):
    return "\n\n".join([doc.page_content for doc in docs])

# ===== 12. RAG é“¾ =====
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# ===== 13. å¼€å§‹å¯¹è¯ =====
print("\n" + "="*50)
print("ğŸ“ AIåŠ©æ•™ï¼ˆåŸºäºæ•™æç‰ˆ - ç»å¯¹ç¦»çº¿ï¼‰")
print("="*50)
print("âœ… å·²é€šè¿‡æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹")
print("æˆ‘ä¼šåŸºäº textbook.txt å›ç­”ä½ çš„é—®é¢˜")
print("è¾“å…¥ 'quit' é€€å‡º")
print("-"*50)

while True:
    question = input("\nğŸ‘¨â€ğŸ“ å­¦ç”Ÿ: ")
    
    if question.lower() == 'quit':
        print("ğŸ‘‹ å†è§ï¼")
        break
    
    print("ğŸ¤– æ­£åœ¨æ£€ç´¢æ•™æ...")
    
    # æ£€ç´¢ç›¸å…³æ–‡æ¡£
    docs = retriever.invoke(question)
    
    # è°ƒç”¨ RAG é“¾
    answer = rag_chain.invoke(question)
    
    print(f"\nğŸ’¡ è€å¸ˆ: {answer}")
    
    # æ˜¾ç¤ºå‚è€ƒæ¥æº
    print("\nğŸ“– å‚è€ƒæ•™ææ®µè½ï¼š")
    for i, doc in enumerate(docs):
        print(f"{i+1}. {doc.page_content[:50]}...")
    print("-"*50)