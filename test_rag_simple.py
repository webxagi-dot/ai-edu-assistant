from langchain_community.chat_models import ChatZhipuAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
import time

print("ğŸš€ å¼€å§‹æµ‹è¯•...")

# 1. å‡†å¤‡ä¸€å°æ®µç¤ºä¾‹æ–‡æœ¬
sample_text = """
Pythonæ˜¯ä¸€ç§è§£é‡Šå‹ã€é¢å‘å¯¹è±¡çš„é«˜çº§ç¼–ç¨‹è¯­è¨€ã€‚
Pythonç”±Guido van Rossumäº1989å¹´å‘æ˜ã€‚
Pythonè¯­æ³•ç®€æ´æ¸…æ™°ï¼Œå¼ºåˆ¶ç”¨ç¼©è¿›ã€‚
Pythonå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚
"""

# 2. åˆ†å‰²æ–‡æœ¬
print("ğŸ“– åˆ†å‰²æ–‡æœ¬...")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)
texts = text_splitter.split_text(sample_text)
print(f"åˆ†å‰²æˆ {len(texts)} æ®µ")

# 3. åˆ›å»º embeddings
print("ğŸ”§ åŠ è½½ embeddings æ¨¡å‹...")
start = time.time()
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
print(f"âœ… embeddings åŠ è½½å®Œæˆï¼Œè€—æ—¶ {time.time()-start:.2f} ç§’")

# 4. åˆ›å»ºå‘é‡æ•°æ®åº“
print("ğŸ—„ï¸ åˆ›å»ºå‘é‡æ•°æ®åº“...")
start = time.time()
vectorstore = Chroma.from_texts(texts=texts, embedding=embeddings)
print(f"âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆï¼Œè€—æ—¶ {time.time()-start:.2f} ç§’")

# 5. æ£€ç´¢æµ‹è¯•
print("ğŸ” æ£€ç´¢æµ‹è¯•...")
retriever = vectorstore.as_retriever()
docs = retriever.get_relevant_documents("Pythonæ˜¯ä»€ä¹ˆï¼Ÿ")

print("\nğŸ“ æ£€ç´¢ç»“æœï¼š")
for i, doc in enumerate(docs):
    print(f"{i+1}. {doc.page_content}")

print("\nâœ… æµ‹è¯•å®Œæˆï¼")