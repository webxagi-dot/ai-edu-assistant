import streamlit as st
from langchain_community.chat_models import ChatZhipuAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import os
import time

# ===== é¡µé¢é…ç½® =====
st.set_page_config(
    page_title="AI æ•™è‚²å¹³å°",
    page_icon="ğŸ“",
    layout="wide"
)

# ===== ä¾§è¾¹æ å¯¼èˆª =====
st.sidebar.title("ğŸ“ AI æ•™è‚²å¹³å°")
page = st.sidebar.radio(
    "é€‰æ‹©åŠŸèƒ½",
    ["ğŸ“š æ™ºèƒ½åŠ©æ•™", "ğŸ“ ä½œæ–‡æ‰¹æ”¹", "âœï¸ ä¹ é¢˜ç”Ÿæˆ"]
)

st.sidebar.markdown("---")
st.sidebar.markdown("### âš™ï¸ å…¨å±€è®¾ç½®")

# API Key è¾“å…¥ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–é»˜è®¤å€¼ï¼‰
default_key = os.getenv("ZHIPU_API_KEY", "1d9ee499e7bb413aaabe015a87b7773c.3UrwmR1C6Ew1gfDy")
api_key = st.sidebar.text_input(
    "æ™ºè°±AI API Key",
    type="password",
    value=default_key
)

# æ¸©åº¦è°ƒèŠ‚
temperature = st.sidebar.slider(
    "å›ç­”æ¸©åº¦",
    min_value=0.0,
    max_value=1.0,
    value=0.3,
    step=0.1
)

# ===== åˆå§‹åŒ– AI =====
@st.cache_resource
def get_llm():
    return ChatZhipuAI(
        api_key=api_key,
        model="glm-4-flash",
        temperature=temperature
    )

if api_key:
    llm = get_llm()

# ===== åŠŸèƒ½1: æ™ºèƒ½åŠ©æ•™ =====
if page == "ğŸ“š æ™ºèƒ½åŠ©æ•™":
    st.title("ğŸ“š æ™ºèƒ½åŠ©æ•™")
    st.markdown("---")
    
    # æ•™æä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ•™ææ–‡ä»¶ï¼ˆ.txtï¼‰",
        type=['txt'],
        key="textbook_uploader"
    )
    
    if uploaded_file is not None:
        # å¤„ç†ç¼–ç 
        try:
            textbook = uploaded_file.getvalue().decode("utf-8")
        except UnicodeDecodeError:
            try:
                textbook = uploaded_file.getvalue().decode("gbk")
            except UnicodeDecodeError:
                st.error("âŒ æ–‡ä»¶ç¼–ç é”™è¯¯ï¼šè¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶æ˜¯ UTF-8 æˆ– GBK ç¼–ç çš„çº¯æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txtï¼‰")
                st.stop()
        
        st.success(f"âœ… å·²åŠ è½½æ•™æï¼š{uploaded_file.name}")
        
        with st.expander("ğŸ“– æ•™æé¢„è§ˆ"):
            st.text(textbook[:500] + "..." if len(textbook) > 500 else textbook)
        
        # åˆå§‹åŒ– RAG
        with st.spinner("ğŸ”§ åˆå§‹åŒ–çŸ¥è¯†åº“..."):
            # åˆ†å‰²æ–‡æœ¬
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=200,
                chunk_overlap=50,
                separators=["\n\n", "\n", "ã€‚", "ï¼›"]
            )
            texts = text_splitter.split_text(textbook)
            
            # åŠ è½½ embeddings
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2",
                model_kwargs={'device': 'cpu'}
            )
            
            # åˆ›å»ºå‘é‡æ•°æ®åº“
            vectorstore = Chroma.from_texts(
                texts=texts,
                embedding=embeddings,
                persist_directory="./chroma_db_assistant"
            )
            
            retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
            
            # æç¤ºè¯æ¨¡æ¿
            template = """ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„è€å¸ˆã€‚è¯·åŸºäºä»¥ä¸‹æ•™æå†…å®¹å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚

æ•™æå†…å®¹ï¼š
{context}

å­¦ç”Ÿé—®é¢˜ï¼š{question}

è¦æ±‚ï¼š
1. å¦‚æœæ•™æä¸­æœ‰ç›¸å…³å†…å®¹ï¼Œè¯·åŸºäºæ•™æå‡†ç¡®å›ç­”
2. å¦‚æœæ•™æä¸­æ²¡æœ‰ï¼Œè¯·è¯´"æ•™æä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œä¸è¿‡æ ¹æ®æˆ‘çš„ç†è§£ï¼š"
3. ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€ï¼Œå¯ä»¥ä¸¾ä¾‹è¯´æ˜

ä½ çš„å›ç­”ï¼š"""
            
            prompt = PromptTemplate.from_template(template)
            
            def format_docs(docs):
                return "\n\n".join([doc.page_content for doc in docs])
            
            rag_chain = (
                {"context": retriever | format_docs, "question": RunnablePassthrough()}
                | prompt
                | llm
                | StrOutputParser()
            )
            
            st.success("âœ… çŸ¥è¯†åº“å‡†å¤‡å°±ç»ªï¼")
        
        # å¯¹è¯ç•Œé¢
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        if prompt := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                with st.spinner("æ€è€ƒä¸­..."):
                    docs = retriever.invoke(prompt)
                    answer = rag_chain.invoke(prompt)
                    st.markdown(answer)
                    
                    with st.expander("ğŸ“– å‚è€ƒæ•™æ"):
                        for i, doc in enumerate(docs):
                            st.text(f"{i+1}. {doc.page_content[:100]}...")
            
            st.session_state.messages.append({"role": "assistant", "content": answer})

# ===== åŠŸèƒ½2: ä½œæ–‡æ‰¹æ”¹ =====
elif page == "ğŸ“ ä½œæ–‡æ‰¹æ”¹":
    st.title("ğŸ“ ä½œæ–‡æ‰¹æ”¹åŠ©æ‰‹")
    st.markdown("---")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        topic = st.text_input("âœï¸ ä½œæ–‡é¢˜ç›®", placeholder="ä¾‹å¦‚ï¼šæˆ‘çš„æ¢¦æƒ³")
        grade_level = st.selectbox(
            "ğŸ“Š å¹´çº§",
            ["å°å­¦", "åˆä¸­", "é«˜ä¸­", "å¤§å­¦"]
        )
        
    with col2:
        word_count = st.number_input("ğŸ“ å­—æ•°è¦æ±‚", min_value=100, max_value=1000, value=500, step=50)
        style = st.selectbox(
            "ğŸ“ æ–‡ä½“",
            ["è®°å™æ–‡", "è®®è®ºæ–‡", "è¯´æ˜æ–‡", "åº”ç”¨æ–‡"]
        )
    
    essay = st.text_area(
        "ğŸ“„ å­¦ç”Ÿä½œæ–‡",
        height=300,
        placeholder="åœ¨è¿™é‡Œç²˜è´´å­¦ç”Ÿçš„ä½œæ–‡..."
    )
    
    if st.button("âœ¨ å¼€å§‹æ‰¹æ”¹", type="primary"):
        if not essay or not topic:
            st.error("è¯·å¡«å†™ä½œæ–‡é¢˜ç›®å’Œå†…å®¹")
        else:
            with st.spinner("AI æ­£åœ¨æ‰¹æ”¹ä¸­..."):
                # æ„å»ºæ‰¹æ”¹æç¤ºè¯
                grading_prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„è¯­æ–‡è€å¸ˆã€‚è¯·å¯¹ä»¥ä¸‹ä½œæ–‡è¿›è¡Œæ‰¹æ”¹ã€‚

ä½œæ–‡é¢˜ç›®ï¼š{topic}
å¹´çº§ï¼š{grade_level}
å­—æ•°è¦æ±‚ï¼š{word_count}å­—
æ–‡ä½“ï¼š{style}

å­¦ç”Ÿä½œæ–‡ï¼š
{essay}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œæ‰¹æ”¹ï¼Œå¹¶ç»™å‡ºç™¾åˆ†åˆ¶æ€»åˆ†ï¼š

1. å†…å®¹ï¼ˆ30åˆ†ï¼‰ï¼šä¸»é¢˜æ˜ç¡®ã€å†…å®¹å……å®ã€è§‚ç‚¹æ¸…æ™°
2. ç»“æ„ï¼ˆ30åˆ†ï¼‰ï¼šå±‚æ¬¡åˆ†æ˜ã€è¿‡æ¸¡è‡ªç„¶ã€é€»è¾‘æ¸…æ™°
3. è¯­è¨€ï¼ˆ30åˆ†ï¼‰ï¼šè¡¨è¾¾å‡†ç¡®ã€è¯æ±‡ä¸°å¯Œã€å¥å¼å¤šæ ·
4. åˆ›æ„ï¼ˆ10åˆ†ï¼‰ï¼šæœ‰æ–°æ„ã€æœ‰ç‰¹è‰²

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
ã€æ€»åˆ†ã€‘XXåˆ†
ã€å†…å®¹è¯„åˆ†ã€‘XXåˆ† è¯„è¯­ï¼š...
ã€ç»“æ„è¯„åˆ†ã€‘XXåˆ† è¯„è¯­ï¼š...
ã€è¯­è¨€è¯„åˆ†ã€‘XXåˆ† è¯„è¯­ï¼š...
ã€åˆ›æ„è¯„åˆ†ã€‘XXåˆ† è¯„è¯­ï¼š...
ã€è¯¦ç»†è¯„è¯­ã€‘...
ã€ä¿®æ”¹å»ºè®®ã€‘...
ã€ç¤ºèŒƒæ®µè½ã€‘...
"""
                
                response = llm.invoke(grading_prompt)
                
                # æ˜¾ç¤ºç»“æœ
                st.success("âœ… æ‰¹æ”¹å®Œæˆï¼")
                
                # è§£æå¹¶æ˜¾ç¤ºè¯„åˆ†
                result_text = response.content
                
                # å°è¯•æå–æ€»åˆ†
                import re
                score_match = re.search(r'ã€æ€»åˆ†ã€‘(\d+)', result_text)
                if score_match:
                    total_score = int(score_match.group(1))
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æ€»åˆ†", f"{total_score}/100")
                    with col2:
                        st.metric("å†…å®¹", re.search(r'ã€å†…å®¹è¯„åˆ†ã€‘(\d+)', result_text).group(1) if re.search(r'ã€å†…å®¹è¯„åˆ†ã€‘(\d+)', result_text) else "?")
                    with col3:
                        st.metric("ç»“æ„", re.search(r'ã€ç»“æ„è¯„åˆ†ã€‘(\d+)', result_text).group(1) if re.search(r'ã€ç»“æ„è¯„åˆ†ã€‘(\d+)', result_text) else "?")
                    with col4:
                        st.metric("è¯­è¨€", re.search(r'ã€è¯­è¨€è¯„åˆ†ã€‘(\d+)', result_text).group(1) if re.search(r'ã€è¯­è¨€è¯„åˆ†ã€‘(\d+)', result_text) else "?")
                
                # æ˜¾ç¤ºå®Œæ•´æ‰¹æ”¹ç»“æœ
                with st.expander("ğŸ“‹ è¯¦ç»†æ‰¹æ”¹ç»“æœ", expanded=True):
                    st.markdown(result_text)

# ===== åŠŸèƒ½3: ä¹ é¢˜ç”Ÿæˆ =====
elif page == "âœï¸ ä¹ é¢˜ç”Ÿæˆ":
    st.title("âœï¸ æ™ºèƒ½ä¹ é¢˜ç”Ÿæˆ")
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        subject = st.selectbox(
            "ğŸ“š ç§‘ç›®",
            ["Pythonç¼–ç¨‹", "æ•°å­¦", "è‹±è¯­", "è¯­æ–‡", "ç‰©ç†"]
        )
        
        topic = st.text_input("ğŸ¯ çŸ¥è¯†ç‚¹", placeholder="ä¾‹å¦‚ï¼šforå¾ªç¯ã€ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹ã€ä¸€èˆ¬ç°åœ¨æ—¶")
        
    with col2:
        difficulty = st.select_slider(
            "ğŸ“Š éš¾åº¦",
            options=["å…¥é—¨", "ç®€å•", "ä¸­ç­‰", "å›°éš¾", "æŒ‘æˆ˜"]
        )
        
        question_type = st.multiselect(
            "ğŸ“ é¢˜å‹",
            ["é€‰æ‹©é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜", "ç¼–ç¨‹é¢˜"],
            default=["é€‰æ‹©é¢˜"]
        )
    
    count = st.number_input("ğŸ“‹ é¢˜ç›®æ•°é‡", min_value=1, max_value=10, value=3)
    
    if st.button("âœ¨ ç”Ÿæˆä¹ é¢˜", type="primary"):
        if not topic:
            st.error("è¯·è¾“å…¥çŸ¥è¯†ç‚¹")
        else:
            with st.spinner("AI æ­£åœ¨å‡ºé¢˜..."):
                # æ„å»ºå‡ºé¢˜æç¤ºè¯
                exercise_prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„{subject}è€å¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆç»ƒä¹ é¢˜ã€‚

ç§‘ç›®ï¼š{subject}
çŸ¥è¯†ç‚¹ï¼š{topic}
éš¾åº¦ï¼š{difficulty}
é¢˜å‹ï¼š{', '.join(question_type)}
é¢˜ç›®æ•°é‡ï¼š{count}

è¦æ±‚ï¼š
1. é¢˜ç›®è¦è¦†ç›–çŸ¥è¯†ç‚¹çš„æ ¸å¿ƒå†…å®¹
2. éš¾åº¦è¦é€‚åˆ{difficulty}æ°´å¹³
3. é¢˜å‹è¦å¤šæ ·åŒ–
4. æä¾›å‚è€ƒç­”æ¡ˆå’Œè§£æ
5. é¢˜ç›®è¡¨è¿°è¦æ¸…æ™°å‡†ç¡®

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºæ¯ä¸ªé¢˜ç›®ï¼š
ã€é¢˜ç›®Xã€‘
é¢˜å‹ï¼š[é¢˜å‹]
é¢˜ç›®ï¼š[é¢˜ç›®å†…å®¹]
ç­”æ¡ˆï¼š[å‚è€ƒç­”æ¡ˆ]
è§£æï¼š[è¯¦ç»†è§£æ]
---
"""
                
                response = llm.invoke(exercise_prompt)
                
                # æ˜¾ç¤ºç»“æœ
                st.success("âœ… ä¹ é¢˜ç”Ÿæˆå®Œæˆï¼")
                
                # åˆ†å‰²å¹¶æ˜¾ç¤ºé¢˜ç›®
                exercises = response.content.split("---")
                for i, exercise in enumerate(exercises):
                    if exercise.strip():
                        with st.expander(f"ğŸ“Œ ç¬¬{i+1}é¢˜", expanded=i==0):
                            st.markdown(exercise)
                            
                            if st.button(f"æŸ¥çœ‹ç­”æ¡ˆ", key=f"ans_{i}"):
                                st.info("ç­”æ¡ˆå·²åœ¨é¢˜ç›®ä¸­æ˜¾ç¤º")